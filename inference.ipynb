{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57152b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamedmafaz/Desktop/OCR Model/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from transformers import SamModel, SamProcessor\n",
    "from transformers import CLIPVisionModel\n",
    "\n",
    "import math\n",
    "import os\n",
    "import tiktoken\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from deepencoder import CLIP_modified, conv_block, DeepEncoder\n",
    "from dataloader import OCR_dataset, ocr_collate\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helper import text_to_token_ids, token_ids_to_text, download_and_load_gpt2\n",
    "from knowledge_transfer import load_weights_into_gpt_modified\n",
    "from model import GPTModel\n",
    "\n",
    "from pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4ae79a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "special_tokens = {\"<image>\": tokenizer.n_vocab+1}\n",
    "tokenizer_modified = tiktoken.Encoding(\n",
    "    name=\"gpt2_with_image\",\n",
    "    pat_str=tokenizer._pat_str,\n",
    "    mergeable_ranks=tokenizer._mergeable_ranks,\n",
    "    special_tokens={**tokenizer._special_tokens, **special_tokens}\n",
    ")\n",
    "\n",
    "vocab_size = tokenizer_modified.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f4a4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 3, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('dataset')[:20]\n",
    "l = len(files)\n",
    "\n",
    "train_frac = 0.8\n",
    "test_frac  = 0.15\n",
    "\n",
    "batch_size = 1\n",
    "device = \"cpu\"\n",
    "\n",
    "train_pos = int(l * train_frac)\n",
    "test_pos  = int(l * test_frac)\n",
    "\n",
    "train_files = files[: train_pos]\n",
    "test_files = files[train_pos : train_pos + test_pos]\n",
    "val_files  = files[train_pos + test_pos : ]\n",
    "\n",
    "len(train_files), len(test_files), len(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7436be4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([16, 8])\n",
      "target_ids: torch.Size([16, 8])\n",
      "images: torch.Size([16, 3, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "train_dl = DataLoader(\n",
    "           dataset=OCR_dataset(\n",
    "               dataset_file_name = 'dataset',\n",
    "               files = train_files,\n",
    "               tokenizer = tokenizer_modified\n",
    "               ),\n",
    "           batch_size=batch_size,\n",
    "           shuffle=True,\n",
    "           collate_fn=ocr_collate,\n",
    "           pin_memory=True,\n",
    "           drop_last = True\n",
    "       )\n",
    "\n",
    "test_dl  = DataLoader(\n",
    "           dataset=OCR_dataset(\n",
    "               dataset_file_name = 'dataset',\n",
    "               files = test_files,\n",
    "               tokenizer = tokenizer_modified\n",
    "               ),\n",
    "           batch_size=batch_size,\n",
    "           shuffle=False,\n",
    "           collate_fn=ocr_collate,\n",
    "           pin_memory=True,\n",
    "           drop_last = True\n",
    "       )\n",
    "\n",
    "val_dl  =  DataLoader(\n",
    "           dataset=OCR_dataset(\n",
    "               dataset_file_name = 'dataset',\n",
    "               files = val_files,\n",
    "               tokenizer = tokenizer_modified\n",
    "               ),\n",
    "           batch_size=batch_size,\n",
    "           shuffle=False,\n",
    "           collate_fn=ocr_collate,\n",
    "           pin_memory=True,\n",
    "           drop_last = True\n",
    "       )\n",
    "\n",
    "one_batch  = next(iter(train_dl))\n",
    "\n",
    "one_batch_input_ids  = one_batch[\"input_ids\"]\n",
    "one_batch_target_ids =  one_batch[\"target_ids\"]\n",
    "one_batch_images     = one_batch[\"images\"]\n",
    "\n",
    "print(f\"input_ids: {one_batch_input_ids.shape}\")\n",
    "print(f\"target_ids: {one_batch_target_ids.shape}\")\n",
    "print(f\"images: {one_batch_images.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a3d19b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAM params: 93,735,472\n",
       "CLIP params: 303,179,776"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam_model = SamModel.from_pretrained(\"facebook/sam-vit-base\").to(device)\n",
    "clip_model = CLIPVisionModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device)\n",
    "deep_encoder = DeepEncoder(sam_model = sam_model, clip_model = clip_model)\n",
    "deep_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dae1420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 1280)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\"     : tokenizer.n_vocab,     # 50257\n",
    "    \"context_length\" : 1024,                  # The maximum number of tokens the model can process at once\n",
    "    \"embedding_dim\"  : 768,                   # The number of features used to represent each token \n",
    "    \"n_heads\"        : 12,\n",
    "    \"n_layers\"       : 12,                    # How many transformer blocks\n",
    "    \"drop_rate\"      : 0.1,\n",
    "    \"qkv_bias\"       : False\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"embedding_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"embedding_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"embedding_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"embedding_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "model_name = \"gpt2-large (774M)\"\n",
    "\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \n",
    "                   \"qkv_bias\": True, \n",
    "                   \"vocab_size\": tokenizer_modified.n_vocab,\n",
    "                   \"vision_dim\": 1280})\n",
    "\n",
    "gpt2 = GPTModel(NEW_CONFIG)\n",
    "gpt2.token_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43735aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"gpt2/OCR_finetuned/gpt2_774M_finetuned.pth\",\n",
    "                        map_location=\"cpu\")\n",
    "\n",
    "gpt2.load_state_dict(checkpoint[\"model_state\"])\n",
    "gpt2.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78df3ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<image>\\nwould have been'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids_to_text(one_batch_input_ids, tokenizer_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f8e2da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwould have been<|endoftext|>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids_to_text(one_batch_target_ids, tokenizer_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63464957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples: 10: 100%|██████████| 10/10 [00:56<00:00,  5.64s/it]\n"
     ]
    }
   ],
   "source": [
    "text = generate_text(\n",
    "        deep_encoder   = deep_encoder,\n",
    "        gpt2           = gpt2,\n",
    "        projector      = deep_encoder.projector,\n",
    "        tokenizer      = tokenizer_modified,\n",
    "        image          = one_batch_images,\n",
    "        prompt         = \"<image>\\n\",\n",
    "        max_new_tokens = 10,\n",
    "        temperature    = 0.6,\n",
    "        top_k          = 100,\n",
    "        device         = \"cpu\",\n",
    "        eos_token      = 0\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f5bdbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "\n",
    "plt.imshow(\n",
    "    one_batch_images.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    ")\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.title(f'prediction: {text.replace(\"<|endoftext|>\", \"\")}')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
